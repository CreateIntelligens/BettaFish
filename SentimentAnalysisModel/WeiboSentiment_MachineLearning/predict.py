# -*- coding: utf-8 -*-
"""
çµ±ä¸€çš„æƒ…æ„Ÿåˆ†æé æ¸¬ç¨‹åº
æ”¯æŒåŠ è¼‰æ‰€æœ‰æ¨¡å‹é€²è¡Œæƒ…æ„Ÿé æ¸¬
"""
import argparse
import os
import re
from typing import Dict, Tuple, List
import warnings
warnings.filterwarnings("ignore")

# å°å…¥æ‰€æœ‰æ¨¡å‹é¡
from bayes_train import BayesModel
from svm_train import SVMModel
from xgboost_train import XGBoostModel
from lstm_train import LSTMModel
from bert_train import BertModel_Custom
from utils import processing


class SentimentPredictor:
    """æƒ…æ„Ÿåˆ†æé æ¸¬å™¨"""
    
    def __init__(self):
        self.models = {}
        self.available_models = {
            'bayes': BayesModel,
            'svm': SVMModel,
            'xgboost': XGBoostModel,
            'lstm': LSTMModel,
            'bert': BertModel_Custom
        }
        
    def load_model(self, model_type: str, model_path: str, **kwargs) -> None:
        """åŠ è¼‰æŒ‡å®šé¡å‹çš„æ¨¡å‹
        
        Args:
            model_type: æ¨¡å‹é¡å‹ ('bayes', 'svm', 'xgboost', 'lstm', 'bert')
            model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾‘
            **kwargs: å…¶ä»–åƒæ•¸ï¼ˆå¦‚BERTçš„é è¨“ç·´æ¨¡å‹è·¯å¾‘ï¼‰
        """
        if model_type not in self.available_models:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹é¡å‹: {model_type}")
        
        if not os.path.exists(model_path):
            print(f"è­¦å‘Š: æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
            return
        
        print(f"åŠ è¼‰ {model_type.upper()} æ¨¡å‹...")
        
        try:
            if model_type == 'bert':
                # BERTéœ€è¦é¡å¤–çš„é è¨“ç·´æ¨¡å‹è·¯å¾‘
                bert_path = kwargs.get('bert_path', './model/chinese_wwm_pytorch')
                model = BertModel_Custom(bert_path)
            else:
                model = self.available_models[model_type]()
            
            model.load_model(model_path)
            self.models[model_type] = model
            print(f"{model_type.upper()} æ¨¡å‹åŠ è¼‰æˆåŠŸ")
            
        except Exception as e:
            print(f"åŠ è¼‰ {model_type.upper()} æ¨¡å‹å¤±æ•—: {e}")
    
    def load_all_models(self, model_dir: str = './model', bert_path: str = './model/chinese_wwm_pytorch') -> None:
        """åŠ è¼‰æ‰€æœ‰å¯ç”¨çš„æ¨¡å‹
        
        Args:
            model_dir: æ¨¡å‹æ–‡ä»¶ç›®éŒ„
            bert_path: BERTé è¨“ç·´æ¨¡å‹è·¯å¾‘
        """
        model_files = {
            'bayes': os.path.join(model_dir, 'bayes_model.pkl'),
            'svm': os.path.join(model_dir, 'svm_model.pkl'),
            'xgboost': os.path.join(model_dir, 'xgboost_model.pkl'),
            'lstm': os.path.join(model_dir, 'lstm_model.pth'),
            'bert': os.path.join(model_dir, 'bert_model.pth')
        }
        
        print("é–‹å§‹åŠ è¼‰æ‰€æœ‰å¯ç”¨æ¨¡å‹...")
        for model_type, model_path in model_files.items():
            self.load_model(model_type, model_path, bert_path=bert_path)
        
        print(f"\nå·²åŠ è¼‰ {len(self.models)} å€‹æ¨¡å‹: {list(self.models.keys())}")
    
    def predict_single(self, text: str, model_type: str = None) -> Dict[str, Tuple[int, float]]:
        """é æ¸¬å–®æ¢æ–‡æœ¬çš„æƒ…æ„Ÿ
        
        Args:
            text: å¾…é æ¸¬æ–‡æœ¬
            model_type: æŒ‡å®šæ¨¡å‹é¡å‹ï¼Œå¦‚æœçˆ²Noneå‰‡ä½¿ç”¨æ‰€æœ‰å·²åŠ è¼‰çš„æ¨¡å‹
            
        Returns:
            Dict[model_type, (prediction, confidence)]
        """
        # æ–‡æœ¬é è™•ç†
        processed_text = processing(text)
        
        if model_type:
            if model_type not in self.models:
                raise ValueError(f"æ¨¡å‹ {model_type} æœªåŠ è¼‰")
            
            prediction, confidence = self.models[model_type].predict_single(processed_text)
            return {model_type: (prediction, confidence)}
        
        # ä½¿ç”¨æ‰€æœ‰æ¨¡å‹é æ¸¬
        results = {}
        for name, model in self.models.items():
            try:
                prediction, confidence = model.predict_single(processed_text)
                results[name] = (prediction, confidence)
            except Exception as e:
                print(f"æ¨¡å‹ {name} é æ¸¬å¤±æ•—: {e}")
                results[name] = (0, 0.0)
        
        return results
    
    def predict_batch(self, texts: List[str], model_type: str = None) -> Dict[str, List[int]]:
        """æ‰¹é‡é æ¸¬æ–‡æœ¬æƒ…æ„Ÿ
        
        Args:
            texts: å¾…é æ¸¬æ–‡æœ¬åˆ—è¡¨
            model_type: æŒ‡å®šæ¨¡å‹é¡å‹ï¼Œå¦‚æœçˆ²Noneå‰‡ä½¿ç”¨æ‰€æœ‰å·²åŠ è¼‰çš„æ¨¡å‹
            
        Returns:
            Dict[model_type, predictions]
        """
        # æ–‡æœ¬é è™•ç†
        processed_texts = [processing(text) for text in texts]
        
        if model_type:
            if model_type not in self.models:
                raise ValueError(f"æ¨¡å‹ {model_type} æœªåŠ è¼‰")
            
            predictions = self.models[model_type].predict(processed_texts)
            return {model_type: predictions}
        
        # ä½¿ç”¨æ‰€æœ‰æ¨¡å‹é æ¸¬
        results = {}
        for name, model in self.models.items():
            try:
                predictions = model.predict(processed_texts)
                results[name] = predictions
            except Exception as e:
                print(f"æ¨¡å‹ {name} é æ¸¬å¤±æ•—: {e}")
                results[name] = [0] * len(texts)
        
        return results
    
    def ensemble_predict(self, text: str, weights: Dict[str, float] = None) -> Tuple[int, float]:
        """é›†æˆé æ¸¬ï¼ˆå¤šå€‹æ¨¡å‹æŠ•ç¥¨ï¼‰
        
        Args:
            text: å¾…é æ¸¬æ–‡æœ¬
            weights: æ¨¡å‹æ¬Šé‡ï¼Œå¦‚æœçˆ²Noneå‰‡å¹³å‡æ¬Šé‡
            
        Returns:
            (prediction, confidence)
        """
        if len(self.models) == 0:
            raise ValueError("æ²’æœ‰åŠ è¼‰ä»»ä½•æ¨¡å‹")
        
        results = self.predict_single(text)
        
        if weights is None:
            weights = {name: 1.0 for name in results.keys()}
        
        # åŠ æ¬Šå¹³å‡
        total_weight = 0
        weighted_prob = 0
        
        for model_name, (pred, conf) in results.items():
            if model_name in weights:
                weight = weights[model_name]
                prob = conf if pred == 1 else 1 - conf
                weighted_prob += prob * weight
                total_weight += weight
        
        if total_weight == 0:
            return 0, 0.5
        
        final_prob = weighted_prob / total_weight
        final_pred = int(final_prob > 0.5)
        final_conf = final_prob if final_pred == 1 else 1 - final_prob
        
        return final_pred, final_conf
    
    def interactive_predict(self):
        """äº¤äº’å¼é æ¸¬æ¨¡å¼"""
        if len(self.models) == 0:
            print("éŒ¯èª¤: æ²’æœ‰åŠ è¼‰ä»»ä½•æ¨¡å‹ï¼Œè«‹å…ˆåŠ è¼‰æ¨¡å‹")
            return
        
        print("\n" + "="*50)
        print("="*50)
        print(f"å·²åŠ è¼‰æ¨¡å‹: {', '.join(self.models.keys())}")
        print("è¼¸å…¥ 'q' é€€å‡ºç¨‹åº")
        print("è¼¸å…¥ 'models' æŸ¥çœ‹æ¨¡å‹åˆ—è¡¨")
        print("è¼¸å…¥ 'ensemble' ä½¿ç”¨é›†æˆé æ¸¬")
        print("-"*50)
        
        while True:
            try:
                text = input("\nè«‹è¼¸å…¥è¦åˆ†æçš„å¾®åšå…§å®¹: ").strip()
                
                if text.lower() == 'q':
                    print("ğŸ‘‹ å†è¦‹ï¼")
                    break
                
                if text.lower() == 'models':
                    print(f"å·²åŠ è¼‰æ¨¡å‹: {list(self.models.keys())}")
                    continue
                
                if text.lower() == 'ensemble':
                    if len(self.models) > 1:
                        pred, conf = self.ensemble_predict(text)
                        sentiment = "ğŸ˜Š æ­£é¢" if pred == 1 else "ğŸ˜ è² é¢"
                        print(f"\nğŸ¤– é›†æˆé æ¸¬çµæœ:")
                        print(f"   æƒ…æ„Ÿå‚¾å‘: {sentiment}")
                        print(f"   ç½®ä¿¡åº¦: {conf:.4f}")
                    else:
                        print("âŒ é›†æˆé æ¸¬éœ€è¦è‡³å°‘2å€‹æ¨¡å‹")
                    continue
                
                if not text:
                    print("âŒ è«‹è¼¸å…¥æœ‰æ•ˆå…§å®¹")
                    continue
                
                # é æ¸¬
                results = self.predict_single(text)
                
                print(f"\nğŸ“ åŸæ–‡: {text}")
                print("ğŸ” é æ¸¬çµæœ:")
                
                for model_name, (pred, conf) in results.items():
                    sentiment = "ğŸ˜Š æ­£é¢" if pred == 1 else "ğŸ˜ è² é¢"
                    print(f"   {model_name.upper():8}: {sentiment} (ç½®ä¿¡åº¦: {conf:.4f})")
                
                # å¦‚æœæœ‰å¤šå€‹æ¨¡å‹ï¼Œé¡¯ç¤ºé›†æˆçµæœ
                if len(results) > 1:
                    ensemble_pred, ensemble_conf = self.ensemble_predict(text)
                    ensemble_sentiment = "ğŸ˜Š æ­£é¢" if ensemble_pred == 1 else "ğŸ˜ è² é¢"
                    print(f"   {'é›†æˆ':8}: {ensemble_sentiment} (ç½®ä¿¡åº¦: {ensemble_conf:.4f})")
                
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ ç¨‹åºè¢«ä¸­æ–·ï¼Œå†è¦‹ï¼")
                break
            except Exception as e:
                print(f"âŒ é æ¸¬éç¨‹ä¸­å‡ºç¾éŒ¯èª¤: {e}")


def main():
    """ä¸»å‡½æ•¸"""
    parser = argparse.ArgumentParser(description='å¾®åšæƒ…æ„Ÿåˆ†æçµ±ä¸€é æ¸¬ç¨‹åº')
    parser.add_argument('--model_dir', type=str, default='./model',
                        help='æ¨¡å‹æ–‡ä»¶ç›®éŒ„')
    parser.add_argument('--bert_path', type=str, default='./model/chinese_wwm_pytorch',
                        help='BERTé è¨“ç·´æ¨¡å‹è·¯å¾‘')
    parser.add_argument('--model_type', type=str, choices=['bayes', 'svm', 'xgboost', 'lstm', 'bert'],
                        help='æŒ‡å®šå–®å€‹æ¨¡å‹é¡å‹é€²è¡Œé æ¸¬')
    parser.add_argument('--text', type=str,
                        help='ç›´æ¥é æ¸¬æŒ‡å®šæ–‡æœ¬')
    parser.add_argument('--interactive', action='store_true', default=True,
                        help='äº¤äº’å¼é æ¸¬æ¨¡å¼ï¼ˆé»˜èªï¼‰')
    parser.add_argument('--ensemble', action='store_true',
                        help='ä½¿ç”¨é›†æˆé æ¸¬')
    
    args = parser.parse_args()
    
    # å‰µå»ºé æ¸¬å™¨
    predictor = SentimentPredictor()
    
    # åŠ è¼‰æ¨¡å‹
    if args.model_type:
        # åŠ è¼‰æŒ‡å®šæ¨¡å‹
        model_files = {
            'bayes': 'bayes_model.pkl',
            'svm': 'svm_model.pkl',
            'xgboost': 'xgboost_model.pkl',
            'lstm': 'lstm_model.pth',
            'bert': 'bert_model.pth'
        }
        model_path = os.path.join(args.model_dir, model_files[args.model_type])
        predictor.load_model(args.model_type, model_path, bert_path=args.bert_path)
    else:
        # åŠ è¼‰æ‰€æœ‰æ¨¡å‹
        predictor.load_all_models(args.model_dir, args.bert_path)
    
    # å¦‚æœæŒ‡å®šäº†æ–‡æœ¬ï¼Œç›´æ¥é æ¸¬
    if args.text:
        if args.ensemble and len(predictor.models) > 1:
            pred, conf = predictor.ensemble_predict(args.text)
            sentiment = "æ­£é¢" if pred == 1 else "è² é¢"
            print(f"æ–‡æœ¬: {args.text}")
            print(f"é›†æˆé æ¸¬: {sentiment} (ç½®ä¿¡åº¦: {conf:.4f})")
        else:
            results = predictor.predict_single(args.text, args.model_type)
            print(f"æ–‡æœ¬: {args.text}")
            for model_name, (pred, conf) in results.items():
                sentiment = "æ­£é¢" if pred == 1 else "è² é¢"
                print(f"{model_name.upper()}: {sentiment} (ç½®ä¿¡åº¦: {conf:.4f})")
    elif args.interactive:
        # äº¤äº’å¼æ¨¡å¼
        predictor.interactive_predict()


if __name__ == "__main__":
    main()